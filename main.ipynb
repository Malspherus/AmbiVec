{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Imports\n"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import logging\n",
    "from rdflib import Graph, Namespace, Literal\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from rdflib import URIRef\n",
    "from rdflib.namespace import RDF\n",
    "from rdflib.namespace import RDFS\n",
    "from rdflib.namespace import SKOS\n",
    "from tqdm import tqdm\n",
    "from TqdmToLogger import TqdmToLogger\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "tqdm.pandas()\n",
    "tqdm_out = TqdmToLogger(logger, level=logging.INFO)\n",
    "\n",
    "#TODO: use numpy for random stuff?\n",
    "#https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.RandomState.html\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gn = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Load/train dictionary\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 14:29:03,371 : INFO : loading projection weights from C:\\Users\\Peter/gensim-data\\glove-wiki-gigaword-100\\glove-wiki-gigaword-100.gz\n",
      "2020-01-23 14:30:13,724 : INFO : loaded (400000, 100) matrix from C:\\Users\\Peter/gensim-data\\glove-wiki-gigaword-100\\glove-wiki-gigaword-100.gz\n"
     ]
    }
   ],
   "source": [
    "gw1 = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Load/train dictionary\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gw3 = api.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# wk = api.load('wiki-english-20171001')\n",
    "\n",
    "# Wiki has to be converted, but JSON is not supported...\n",
    "# wiki = gensim.corpora.WikiCorpus(wk)\n",
    "\n",
    "# Train and save\n",
    "# model = gensim.models.Word2Vec(wk, workers=4)\n",
    "# 14774682 raw words (853473 effective words) took 610.2s with 3 workers\n",
    "\n",
    "# with tempfile.NamedTemporaryFile(prefix='wiki-english-20171001-model-', delete=False) as tmp:\n",
    "#    temporary_filepath = tmp.name\n",
    "#    model.save(temporary_filepath)\n",
    "\n",
    "# Load\n",
    "# model = gensim.models.Word2Vec.load(temporary_filepath)\n",
    "# wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = gw1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KBpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% Load KG\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 15:06:31,803 : INFO : Loaded graph with 730673 triples\n"
     ]
    }
   ],
   "source": [
    "kb = Graph()\n",
    "kb.parse(\"C:/Users/Peter/Uni/MA/KBpedia/kbpedia_reference_concepts.n3\", format=\"n3\")\n",
    "logger.info(f\"Loaded graph with {len(kb)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = kb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBpedia disjointDomain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 14:57:50,384 : INFO : Loaded graph with 15323 triples\n"
     ]
    }
   ],
   "source": [
    "db = Graph()\n",
    "db.parse(\"C:/Users/Peter/Uni/MA/DBpedia/mappingbased-objects_lang=en_disjointDomain.ttl\", format=\"ttl\")\n",
    "logger.info(f\"Loaded graph with {len(db)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBpedia disjointRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 14:57:53,742 : INFO : Loaded graph with 17461 triples\n"
     ]
    }
   ],
   "source": [
    "db2 = Graph()\n",
    "db2.parse(\"C:/Users/Peter/Uni/MA/DBpedia/mappingbased-objects_lang=en_disjointRange.ttl\", format=\"ttl\")\n",
    "logger.info(f\"Loaded graph with {len(db2)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Own KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 14:53:31,540 : INFO : Loaded graph with 44 triples\n"
     ]
    }
   ],
   "source": [
    "tg = Graph()\n",
    "tg.parse(\"KGDemo.ttl\", format=\"ttl\")\n",
    "logger.info(f\"Loaded graph with {len(tg)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Currently unused"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Build subset of dictionary, might improve performance\n",
    "def restrict_w2v(w2v, restricted_word_set):\n",
    "    new_vectors = []\n",
    "    new_vocab = {}\n",
    "    new_index2entity = []\n",
    "    new_vectors_norm = []\n",
    "\n",
    "    for i in range(len(w2v.vocab)):\n",
    "        word = w2v.index2entity[i]\n",
    "        vec = w2v.vectors[i]\n",
    "        vocab = w2v.vocab[word]\n",
    "        vec_norm = w2v.vectors_norm[i]\n",
    "        if word in restricted_word_set:\n",
    "            vocab.index = len(new_index2entity)\n",
    "            new_index2entity.append(word)\n",
    "            new_vocab[word] = vocab\n",
    "            new_vectors.append(vec)\n",
    "            new_vectors_norm.append(vec_norm)\n",
    "\n",
    "    w2v.vocab = new_vocab\n",
    "    w2v.vectors = np.array(new_vectors)\n",
    "    w2v.index2entity = np.array(new_index2entity)\n",
    "    w2v.index2word = np.array(new_index2entity)\n",
    "    w2v.vectors_norm = np.array(new_vectors_norm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Use dictionary to find similar vectors\n",
    "def most_similar_to_given_vec(vec, entities_list):\n",
    "    return wv.similar_by_vector(vector = entities_list[np.argmax([wv.cosine_similarities(vec, [entity])[0] for entity in entities_list])], topn=1)[0][0]\n",
    "\n",
    "# Demo for most_similar_to_given_vec(..)\n",
    "entities_list = [wv['tokyo'], wv['vienna']]\n",
    "most_similar_to_given_vec(wv['tokyo'], entities_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#From name to node\n",
    "def toNode(name):\n",
    "    for node in nodeVectors.index:\n",
    "        if getPreferredTitle(node) == name:\n",
    "            return node\n",
    "    return None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#De-vectorise nodes and relations\n",
    "def deVectorise(vec):\n",
    "    if vec['source_type'] == 'node':\n",
    "        source = nodeVectors.copy()\n",
    "    else:\n",
    "        source = relationVectors.copy()\n",
    "    \n",
    "    source['dist'] = source.apply(lambda row: wv.cosine_similarities(list(vec['vec']), [list(row['vec'])])[0], axis = 1)\n",
    "    source = source.sort_values(by='dist', ascending=False)\n",
    "    \n",
    "    return source.iloc[0, source.columns.get_loc(vec['source_type'])]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#De-vecotrise nodes and relations generated by methods\n",
    "logger.info(f\"De-Vectorising...\")\n",
    "res['target'] = res.progress_apply(lambda row: deVectorise(row), axis = 1)\n",
    "res = res[['method', 'config', 'source_type', 'source', 'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dictionary quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare all dictionaries\n",
    "dicts = {\"gn\": gn, \"gw1\": gw1, \"gw3\": gw3}\n",
    "\n",
    "for i in dicts:\n",
    "    dic = dicts[i]\n",
    "    \n",
    "    #Minus means arrow from R to L\n",
    "    hasCapital = dic[\"tokyo\"] - dic[\"japan\"]\n",
    "    isCapitalOf = dic[\"japan\"] - dic[\"tokyo\"]\n",
    "    \n",
    "    #Calculate results of relation\n",
    "    est_france = dic[\"paris\"] + isCapitalOf\n",
    "    est_paris = dic[\"france\"] + hasCapital\n",
    "    \n",
    "    print(f\"Dictionary: {i}\")\n",
    "    print(f\"est_France to France: {dic.cosine_similarities(est_france, [dic['france']])}\")\n",
    "    print(f\"est_Paris to Paris: {dic.cosine_similarities(est_paris, [dic['paris']])}\")\n",
    "    print(f\"est_France to Paris: {dic.cosine_similarities(est_france, [dic['paris']])}\")\n",
    "    print(f\"est_Paris to France: {dic.cosine_similarities(est_paris, [dic['france']])}\")\n",
    "    print(f\"Paris to France: {dic.cosine_similarities(dic['paris'], [dic['france']])}\")\n",
    "    print(f\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Similarity: {wv.cosine_similarities(wv['white'], [wv['black']])[0]}\\n\")\n",
    "\n",
    "print(\"Inverted node 'white':\")\n",
    "for d in wv.similar_by_vector(vector = -1*wv['white']):\n",
    "    print(f\"Distance of '{d[0]}' to !white: {d[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getPreferredTitle(n, lang=\"en\"):\n",
    "    label = g.preferredLabel(n, lang=lang)\n",
    "\n",
    "    #if type(n) is not type(Literal(\"\")): #only labels should be of type literal\n",
    "    if label == []:\n",
    "        return n.rsplit('/', 1)[-1].replace('_', ' ').replace(',', '').lower() #TODO: replace \"()\"?\n",
    "    else:\n",
    "        return label[0][1].value.lower()\n",
    "    #else:\n",
    "    #    return None\n",
    "\n",
    "#Returns [vec, isMultipart, multipart-matched-%]\n",
    "def toVector(n):\n",
    "    title = getPreferredTitle(n)\n",
    "    #if title is None:\n",
    "    #    return [None, None, None]\n",
    "    \n",
    "    #In case of multiple words in title use mean of individual vectors\n",
    "    if \" \" in title:\n",
    "        subvecs = []\n",
    "        count = 0\n",
    "        hit = 0\n",
    "        for word in title.split(\" \"):\n",
    "            count += 1\n",
    "            try:\n",
    "                subvecs += [wv[word]]\n",
    "                hit += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "        \n",
    "        if hit > 0:\n",
    "            return [sum(subvecs)/hit, True, hit/count]\n",
    "        else:\n",
    "            return [None, True, 0]\n",
    "    else:\n",
    "        try:\n",
    "            return [wv[title], False, False]\n",
    "        except KeyError:\n",
    "            return [None, False, False]\n",
    "\n",
    "#Methods to ambiguify nodes and relations\n",
    "def select(inp, obj={'perc': None, 'num': None}):\n",
    "    if len(obj) > 1:\n",
    "        raise TypeError(\"Please give exactly one of percentage or number\")\n",
    "        \n",
    "    for val in obj:\n",
    "        if val == 'perc':\n",
    "            return inp.sample(frac=obj[val], replace=True)\n",
    "        else:\n",
    "            return inp.sample(n=obj[val], replace=True)\n",
    "\n",
    "def ambiguify(config, nodeVectors, relationVectors):\n",
    "    out = pd.DataFrame()\n",
    "    for target in config: #can be \"nodes\" or \"relations\"\n",
    "        for method in config[target]: #matches the name of the method\n",
    "            for instance in config[target][method]: #once for every instance of the method config\n",
    "                for val in instance['amount']: #the amount of elements to be changed\n",
    "                    logger.info(f\"Ambiguifying {target} with {method} (parameters: {instance})\")\n",
    "                    if target == 'nodes':\n",
    "                        inp = nodeVectors\n",
    "                    else:\n",
    "                        inp = relationVectors\n",
    "                    \n",
    "                    selres = select(inp, instance['amount'])\n",
    "                    conf = instance.get('param', None)\n",
    "                    sourceColumn = target[0:-1]\n",
    "                    rep = pd.DataFrame()\n",
    "                    \n",
    "                    rep[['method', 'config', 'source_type', 'source', 'target']] = selres.progress_apply(lambda sel: pd.Series([\n",
    "                        method,\n",
    "                        str(instance),\n",
    "                        sourceColumn,\n",
    "                        sel[sourceColumn],\n",
    "                        methods[target][method](sel.copy(), inp.copy(), conf)[sourceColumn].iloc[0]\n",
    "                    ]), axis=1)\n",
    "                    \n",
    "                    out = out.append(rep, ignore_index=True)\n",
    "    return out\n",
    "\n",
    "#Modify triple and save as new\n",
    "def modTriple(row, g2, useObject = False, retry=False):\n",
    "    if row['source_type'] == 'relation':\n",
    "        logger.debug(\"Replacing r\")\n",
    "        fil = fullVectors['p'] == row['source']\n",
    "    else:\n",
    "        if useObject:\n",
    "            logger.debug(\"Replacing o\")\n",
    "            fil = fullVectors['o'] == row['source']\n",
    "        else:\n",
    "            logger.debug(\"Replacing s\")\n",
    "            fil = fullVectors['s'] == row['source']\n",
    "    \n",
    "    res = fullVectors[fil]\n",
    "\n",
    "    if len(res) == 0:\n",
    "        if not retry:\n",
    "            return modTriple(row, g2, useObject= not useObject, retry=True)\n",
    "        else:\n",
    "            logger.error(f\"Could not find original triple!\")\n",
    "    else:\n",
    "        rep = res.sample(n=1)\n",
    "\n",
    "        #add row to graph with changed content\n",
    "        if row['source_type'] == 'relation':\n",
    "            g2.add((rep['s'].iloc[0], row['target'], rep['o'].iloc[0]))\n",
    "            logger.debug(f\"{(rep['s'].iloc[0], row['target'], rep['o'].iloc[0])}\")\n",
    "            return (rep['s'].iloc[0], row['target'], rep['o'].iloc[0])\n",
    "        else:\n",
    "            if useObject:\n",
    "                g2.add((rep['s'].iloc[0], rep['p'].iloc[0], row['target']))\n",
    "                logger.debug(f\"{(rep['s'].iloc[0], rep['p'].iloc[0], row['target'])}\")\n",
    "                return (rep['s'].iloc[0], rep['p'].iloc[0], row['target'])\n",
    "            else:\n",
    "                g2.add((row['target'], rep['p'].iloc[0], rep['o'].iloc[0]))\n",
    "                logger.debug(f\"{(row['target'], rep['p'].iloc[0], rep['o'].iloc[0])}\")\n",
    "                return (row['target'], rep['p'].iloc[0], rep['o'].iloc[0])\n",
    "        \n",
    "def populateAdditions(res, g2):\n",
    "    logger.info(f\"Populatig graph\")\n",
    "    \n",
    "    out = pd.DataFrame()\n",
    "    out[['s', 'p', 'o']] = res.progress_apply(lambda row: pd.Series(modTriple(row, g2, useObject=(random.random() >= 0.5))), axis=1)\n",
    "    \n",
    "    return out\n",
    "\n",
    "#Returns percent of ambiguity in the graph\n",
    "def calculateAmbiguity(fullVectors, nodeVectors, relationVectors):\n",
    "    #for relations\n",
    "    weights = relationVectors['total'] - relationVectors['lost'] - relationVectors['zero_vector']\n",
    "    relAmbig = np.average(relationVectors['mean_dist'], weights=weights)\n",
    "    \n",
    "    #for nodes\n",
    "    weights = nodeVectors['total']\n",
    "    nodeAmbig = np.average(nodeVectors['est_dist'], weights=weights)\n",
    "    \n",
    "    #mean of ambiguities of nodes and vectors, weight by nodes 2:1 relation\n",
    "    totAmbig = np.average([relAmbig, nodeAmbig], weights=[2, 1])\n",
    "    \n",
    "    #transform -1..1 where 1 is the least ambiguous to 0..1 where 1 is the most ambiguous\n",
    "    return 1-((1+totAmbig)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup methods\n",
    "def rand(inp, source, conf):\n",
    "    return source.sample(n=1)\n",
    "\n",
    "#Find result with specific distance\n",
    "def dist(inp, source, conf):\n",
    "    if conf == None:\n",
    "        dist = 1\n",
    "    else:\n",
    "        dist = conf.get('dist', 1)\n",
    "        \n",
    "    dist = min(max(dist, 0), len(source.index)-1)\n",
    "    \n",
    "    #use pandas to get top-n, if dist is same move inp to the top\n",
    "    source[['dist', 'isInp']] = source.apply(lambda row: pd.Series([wv.cosine_similarities(list(inp['vec']), [list(row['vec'])])[0], inp[0] == row[0]]), axis = 1)\n",
    "    source = source.sort_values(by=['dist', 'isInp'], ascending=False)\n",
    "    \n",
    "    logger.debug(f\"source:\\n{source}\")\n",
    "    \n",
    "    logger.debug(f\"dist: {dist}\")\n",
    "    logger.debug(f\"choice:\\n{source.iloc[[dist]]}\")\n",
    "\n",
    "    return source.iloc[[dist]].drop(['dist', 'isInp'], axis=1)\n",
    "\n",
    "#Find result with specific closeness\n",
    "def closeness(inp, source, conf):\n",
    "    if conf == None:\n",
    "        closeness = 1\n",
    "    else:\n",
    "        closeness = conf.get('closeness', 1)\n",
    "        \n",
    "    closeness = min(max(closeness, 0), 2) #0 is equal to the input, 2 is its inverse\n",
    "    \n",
    "    #use pandas to get dists\n",
    "    source[['dist', 'isInp']] = source.apply(lambda row: pd.Series([wv.cosine_similarities(list(inp['vec']), [list(row['vec'])])[0], inp[0] == row[0]]), axis = 1)\n",
    "    resIndex = source['dist'].add(closeness-1).abs().idxmin()\n",
    "    \n",
    "    return source.iloc[[resIndex]].drop(['dist', 'isInp'], axis=1)\n",
    "\n",
    "#Find result closest to inverse input vector\n",
    "def negative(inp, source, conf):\n",
    "    return closeness(inp, source, {'closeness': 2})\n",
    "\n",
    "methods = {\n",
    "    'nodes':{\n",
    "        'random': rand,\n",
    "        'dist': dist,\n",
    "        'closeness': closeness,\n",
    "        'negative': negative\n",
    "    },\n",
    "    'relations': {\n",
    "        'random': rand,\n",
    "        'dist': dist,\n",
    "        'closeness': closeness,\n",
    "        'negative': negative\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertGraph(g):\n",
    "    logger.info(f\"Converting graph\")\n",
    "    length = 0\n",
    "    for s, p, o in g.triples((None, None, None)):\n",
    "        length += 1\n",
    "\n",
    "    fullVectors = []\n",
    "    for s, p, o in tqdm(g.triples((None, None, None)), total=length, file=tqdm_out, mininterval=2):\n",
    "        fullVectors += [[s, p, o]]\n",
    "\n",
    "    return pd.DataFrame(data=fullVectors, columns=['s', 'p', 'o'])\n",
    "\n",
    "def vectorifyGraph(fullVectors):\n",
    "    logger.info(f\"Vecotrifying graph\")\n",
    "\n",
    "    logger.info('Subject vectors')\n",
    "    fullVectors[['s_vec', 's_is_multipart', 's_multipart_%']] = fullVectors.progress_apply(lambda row: pd.Series(toVector(row['s'])), axis=1)\n",
    "\n",
    "    logger.info('Object vectors')\n",
    "    fullVectors[['o_vec', 'o_is_multipart', 'o_multipart_%']] = fullVectors.progress_apply(lambda row: pd.Series(toVector(row['o'])), axis=1)\n",
    "\n",
    "    logger.info('Relation vectors')\n",
    "    fullVectors[['r_vec', 'is_zero_vector_relation']] = fullVectors.progress_apply(lambda row: pd.Series([\n",
    "        row['o_vec']-row['s_vec'] if row['o_vec'] is not None and row['s_vec'] is not None else None,\n",
    "        np.array_equal(row['o_vec']-row['s_vec'], [0]*len(row['o_vec'])) if row['o_vec'] is not None and row['s_vec'] is not None else False\n",
    "    ]), axis=1)\n",
    "    \n",
    "    return fullVectors\n",
    "\n",
    "def calculateNodeEstimates(fullVectors, relationVectors):\n",
    "    logger.info(f\"Calculating node estimates\")\n",
    "    \n",
    "    def helper(row, op, same, other):\n",
    "        #Select the relation vector if there is one\n",
    "        relVecs = relationVectors[relationVectors['relation'] == row['p']]\n",
    "        if len(relVecs) > 0:\n",
    "            rVec = relVecs['vec'].iloc[0]\n",
    "        else:\n",
    "            rVec = None\n",
    "        \n",
    "        #Calculate the estimate\n",
    "        if row[other] is not None and rVec is not None:\n",
    "            est = op(row[other], rVec)\n",
    "        else:\n",
    "            est = None\n",
    "        \n",
    "        #Calculate the distance\n",
    "        if est is not None and row[same] is not None:\n",
    "            dist = wv.cosine_similarities(row[same], [est])[0]\n",
    "        else:\n",
    "            dist = None\n",
    "        \n",
    "        return pd.Series([est, dist], dtype='object')\n",
    "\n",
    "    logger.info(f\"Subject estimates\")\n",
    "    fullVectors[['s_est', 's_est_dist']] = fullVectors.progress_apply(helper, args=[np.subtract, 's_vec', 'o_vec'], axis=1)\n",
    "    \n",
    "    logger.info(f\"Object estimates\")\n",
    "    fullVectors[['o_est', 'o_est_dist']] = fullVectors.progress_apply(helper, args=[np.add, 'o_vec', 's_vec'], axis=1)\n",
    "    \n",
    "    #Workaround for readability as pandas is equaling NaN and None\n",
    "    fullVectors = fullVectors.astype({'s_est': 'object', 's_est_dist': 'object', 'o_est': 'object', 'o_est_dist': 'object'})\n",
    "    fullVectors.loc[fullVectors['s_est'].isna(), 's_est'] = None\n",
    "    fullVectors.loc[fullVectors['s_est_dist'].isna(), 's_est_dist'] = None\n",
    "    fullVectors.loc[fullVectors['o_est'].isna(), 'o_est'] = None\n",
    "    fullVectors.loc[fullVectors['o_est_dist'].isna(), 'o_est_dist'] = None\n",
    "    \n",
    "    return fullVectors\n",
    "\n",
    "def generateNodeVectors(fullVectors):\n",
    "    logger.info(f\"Generating nodeVectors\")\n",
    "    \n",
    "    #Rename and merge\n",
    "    logger.debug(f\"Renaming and merging\")\n",
    "    subjectVectors = fullVectors[['s', 's_vec', 's_is_multipart', 's_multipart_%', 's_est', 's_est_dist']].rename(columns={'s': 'node',\n",
    "                                                                                                    's_vec': 'vec',\n",
    "                                                                                                    's_is_multipart': 'is_multipart',\n",
    "                                                                                                    's_multipart_%': 'multipart_%',\n",
    "                                                                                                    's_est': 'est',\n",
    "                                                                                                    's_est_dist': 'est_dist'})\n",
    "    objectVectors = fullVectors[['o', 'o_vec', 'o_is_multipart', 'o_multipart_%', 'o_est', 'o_est_dist']].rename(columns={'o': 'node',\n",
    "                                                                                                   'o_vec': 'vec',\n",
    "                                                                                                   'o_is_multipart': 'is_multipart',\n",
    "                                                                                                   'o_multipart_%': 'multipart_%',\n",
    "                                                                                                   'o_est': 'est',\n",
    "                                                                                                   'o_est_dist': 'est_dist'})\n",
    "    nodeVectors = pd.concat([subjectVectors, objectVectors], ignore_index=True)\n",
    "    \n",
    "    #Remove duplicates\n",
    "    logger.debug(f\"Grouping\")\n",
    "    nodeGroup = nodeVectors.groupby('node')\n",
    "\n",
    "    logger.debug(f\"Using first for vector\")\n",
    "    nodeVectors = nodeGroup.first().reset_index() #TODO: this is really slow\n",
    "    \n",
    "    logger.debug(f\"Calculating totals\")\n",
    "    nodeVectors['total'] = nodeGroup.size().reset_index(drop=True)\n",
    "    \n",
    "    logger.debug(f\"Calculating estimates\")\n",
    "    nodeVectors['est'] = nodeGroup['est'].apply(np.mean).reset_index(drop=True)\n",
    "    \n",
    "    #Workaround as pandas is equaling NaN and None\n",
    "    nodeVectors = nodeVectors.astype({'est': 'object', 'vec': 'object'})\n",
    "    nodeVectors.loc[nodeVectors['est'].isna(), 'est'] = None\n",
    "    nodeVectors.loc[nodeVectors['vec'].isna(), 'vec'] = None\n",
    "    \n",
    "    logger.debug(f\"Calculating estimate distances\")\n",
    "    nodeVectors['est_dist'] = nodeVectors.apply(lambda row: wv.cosine_similarities(list(row['est']), [list(row['vec'])])[0] if row['est'] is not None and row['vec'] is not None else None, axis=1)\n",
    "    \n",
    "    logger.debug(f\"Calculating mean/min/max of distances\")\n",
    "    nodeVectors['mean_est_dist'] = nodeGroup['est_dist'].apply(np.mean).reset_index(drop=True)\n",
    "    nodeVectors['min_est_dist'] = nodeGroup['est_dist'].apply(np.min).reset_index(drop=True)\n",
    "    nodeVectors['max_est_dist'] = nodeGroup['est_dist'].apply(np.max).reset_index(drop=True)\n",
    "    \n",
    "    #Split into nodeVectors and lostNodes\n",
    "    logger.debug(f\"Splitting into nodeVectors and lostNodes\")\n",
    "    lostNodes = nodeVectors[nodeVectors['vec'].isnull()].reset_index(drop=True).drop(columns=['vec', 'est_dist', 'mean_est_dist', 'min_est_dist', 'max_est_dist'])\n",
    "    nodeVectors = nodeVectors.dropna().reset_index(drop=True)\n",
    "    logger.info(\"Done\")\n",
    "    \n",
    "    return nodeVectors, lostNodes\n",
    "\n",
    "def generateRelationVectors(fullVectors):\n",
    "    logger.info(f\"Generating relationVectors\")\n",
    "    \n",
    "    logger.debug(f\"Grouping\")\n",
    "    relationVectors = fullVectors.groupby('p')['r_vec'].apply(np.mean).reset_index().rename(columns={'p': 'relation', 'r_vec': 'vec'})\n",
    "\n",
    "    logger.debug(f\"Calculating total, lost, zero_vector and quality\")\n",
    "    relationVectors['total'] = fullVectors.groupby('p')['p'].count().reset_index(drop=True)\n",
    "    relationVectors['lost'] = fullVectors.groupby('p')['r_vec'].apply(lambda x: x.isnull().sum()).reset_index(drop=True)\n",
    "    relationVectors['zero_vector'] = fullVectors.groupby('p')['is_zero_vector_relation'].sum().astype(int).reset_index(drop=True)\n",
    "    relationVectors['quality'] = relationVectors.apply(lambda row: 1-(row['lost']+row['zero_vector'])/row['total'], axis=1)\n",
    "\n",
    "    #TODO: labels are counted as lost nodes\n",
    "    #Split into relationVectors and lostRelations\n",
    "    logger.debug(f\"Splitting into relationVectors and lostRelations\")\n",
    "    lostRelations = relationVectors[np.bitwise_or(\n",
    "        relationVectors['vec'].isnull(),\n",
    "        relationVectors['total']-relationVectors['lost']-relationVectors['zero_vector'] == 0\n",
    "    )].reset_index(drop=True).drop(columns=['vec', 'quality'])\n",
    "    relationVectors = relationVectors[np.bitwise_and(\n",
    "        relationVectors['vec'].notnull(),\n",
    "        relationVectors['total']-relationVectors['lost']-relationVectors['zero_vector'] != 0\n",
    "    )].reset_index(drop=True)\n",
    "    \n",
    "    #Min/max/average distance of every full vector of this relation type to mean vector\n",
    "    logger.debug(f\"Calculating min, max and average distances\")\n",
    "    def helper_dist(row):\n",
    "        vectors = fullVectors[fullVectors['p'] == row['relation']]\n",
    "\n",
    "        #filter out None and zero-vector\n",
    "        vectors = vectors[vectors['is_zero_vector_relation'] == False]\n",
    "        vectors = vectors['r_vec'].dropna().reset_index(drop=True)\n",
    "\n",
    "        sims = wv.cosine_similarities(row['vec'], list(vectors))\n",
    "        return [np.min(sims), np.max(sims), np.mean(sims)]\n",
    "\n",
    "    relationVectors[['min_dist', 'max_dist', 'mean_dist']] = relationVectors.apply(lambda row: pd.Series(helper_dist(row)), axis=1)\n",
    "    logger.info(\"Done\")\n",
    "    \n",
    "    return relationVectors, lostRelations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 15:06:31,852 : INFO : Converting graph\n",
      "2020-01-23 15:06:35,453 : INFO : 0%|          | 0/730673 [00:00<?, ?it/s]\n",
      "2020-01-23 15:06:38,035 : INFO : 41%|####1     | 302040/730673 [00:02<00:03, 117059.91it/s]\n",
      "2020-01-23 15:06:40,036 : INFO : 93%|#########3| 680935/730673 [00:04<00:00, 132203.81it/s]\n",
      "2020-01-23 15:06:40,324 : INFO : 100%|##########| 730673/730673 [00:04<00:00, 150074.74it/s]\n"
     ]
    }
   ],
   "source": [
    "convertedGraph = convertGraph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 15:06:40,933 : INFO : Vecotrifying graph\n",
      "2020-01-23 15:06:40,935 : INFO : Subject vectors\n",
      "100%|██████████| 730673/730673 [08:40<00:00, 1403.41it/s] \n",
      "2020-01-23 15:15:21,674 : INFO : Object vectors\n",
      "100%|██████████| 730673/730673 [14:01<00:00, 867.85it/s]   \n",
      "2020-01-23 15:29:23,775 : INFO : Relation vectors\n",
      " 21%|██▏       | 156999/730673 [02:05<05:52, 1626.85it/s] "
     ]
    }
   ],
   "source": [
    "fullVectors = vectorifyGraph(convertedGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 14:58:38,125 : INFO : Generating relationVectors\n",
      "2020-01-23 14:58:38,525 : INFO : Done\n"
     ]
    }
   ],
   "source": [
    "relationVectors, lostRelations = generateRelationVectors(fullVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 14:58:38,533 : INFO : Calculating node estimates\n",
      "2020-01-23 14:58:38,535 : INFO : Subject estimates\n",
      "100%|██████████| 15323/15323 [00:32<00:00, 465.31it/s]\n",
      "2020-01-23 14:59:11,476 : INFO : Object estimates\n",
      "100%|██████████| 15323/15323 [00:32<00:00, 474.24it/s]\n"
     ]
    }
   ],
   "source": [
    "fullVectors = calculateNodeEstimates(fullVectors, relationVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 14:59:43,835 : INFO : Generating nodeVectors\n",
      "2020-01-23 15:01:16,794 : INFO : Done\n"
     ]
    }
   ],
   "source": [
    "nodeVectors, lostNodes = generateNodeVectors(fullVectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View calculated values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 15323\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>s_vec</th>\n",
       "      <th>s_is_multipart</th>\n",
       "      <th>s_multipart_%</th>\n",
       "      <th>o_vec</th>\n",
       "      <th>o_is_multipart</th>\n",
       "      <th>o_multipart_%</th>\n",
       "      <th>r_vec</th>\n",
       "      <th>is_zero_vector_relation</th>\n",
       "      <th>s_est</th>\n",
       "      <th>s_est_dist</th>\n",
       "      <th>o_est</th>\n",
       "      <th>o_est_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://dbpedia.org/resource/San_Dieguito_Academy</td>\n",
       "      <td>http://dbpedia.org/ontology/district</td>\n",
       "      <td>http://dbpedia.org/resource/San_Dieguito_Union...</td>\n",
       "      <td>[0.7092967, 0.06972667, -0.16728997, 0.1431166...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.40800336, 0.07011834, -0.06817766, 0.084918...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.30129334, 0.00039166957, 0.09911231, -0.05...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.5581451, 0.22082241, -0.19708529, 0.0857053...</td>\n",
       "      <td>0.765528</td>\n",
       "      <td>[0.559155, -0.0809774, -0.03838235, 0.14232962...</td>\n",
       "      <td>0.738248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://dbpedia.org/resource/John_Dickinson_Hig...</td>\n",
       "      <td>http://dbpedia.org/ontology/district</td>\n",
       "      <td>http://dbpedia.org/resource/Red_Clay_Consolida...</td>\n",
       "      <td>[0.20313275, 0.2372875, -0.23126301, -0.378601...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.046342008, 0.2666352, -0.1983188, -0.06838...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.24947476, 0.029347703, 0.032944217, 0.3102...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.10379972, 0.41733927, -0.3272264, -0.067597...</td>\n",
       "      <td>0.852485</td>\n",
       "      <td>[0.052991018, 0.086583436, -0.10235539, -0.379...</td>\n",
       "      <td>0.832069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   s  \\\n",
       "0   http://dbpedia.org/resource/San_Dieguito_Academy   \n",
       "1  http://dbpedia.org/resource/John_Dickinson_Hig...   \n",
       "\n",
       "                                      p  \\\n",
       "0  http://dbpedia.org/ontology/district   \n",
       "1  http://dbpedia.org/ontology/district   \n",
       "\n",
       "                                                   o  \\\n",
       "0  http://dbpedia.org/resource/San_Dieguito_Union...   \n",
       "1  http://dbpedia.org/resource/Red_Clay_Consolida...   \n",
       "\n",
       "                                               s_vec  s_is_multipart  \\\n",
       "0  [0.7092967, 0.06972667, -0.16728997, 0.1431166...            True   \n",
       "1  [0.20313275, 0.2372875, -0.23126301, -0.378601...            True   \n",
       "\n",
       "  s_multipart_%                                              o_vec  \\\n",
       "0             1  [0.40800336, 0.07011834, -0.06817766, 0.084918...   \n",
       "1             1  [-0.046342008, 0.2666352, -0.1983188, -0.06838...   \n",
       "\n",
       "   o_is_multipart o_multipart_%  \\\n",
       "0            True             1   \n",
       "1            True             1   \n",
       "\n",
       "                                               r_vec  is_zero_vector_relation  \\\n",
       "0  [-0.30129334, 0.00039166957, 0.09911231, -0.05...                    False   \n",
       "1  [-0.24947476, 0.029347703, 0.032944217, 0.3102...                    False   \n",
       "\n",
       "                                               s_est s_est_dist  \\\n",
       "0  [0.5581451, 0.22082241, -0.19708529, 0.0857053...   0.765528   \n",
       "1  [0.10379972, 0.41733927, -0.3272264, -0.067597...   0.852485   \n",
       "\n",
       "                                               o_est o_est_dist  \n",
       "0  [0.559155, -0.0809774, -0.03838235, 0.14232962...   0.738248  \n",
       "1  [0.052991018, 0.086583436, -0.10235539, -0.379...   0.832069  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length: {len(fullVectors)}\")\n",
    "fullVectors.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>s_vec</th>\n",
       "      <th>s_is_multipart</th>\n",
       "      <th>s_multipart_%</th>\n",
       "      <th>o_vec</th>\n",
       "      <th>o_is_multipart</th>\n",
       "      <th>o_multipart_%</th>\n",
       "      <th>r_vec</th>\n",
       "      <th>is_zero_vector_relation</th>\n",
       "      <th>s_est</th>\n",
       "      <th>s_est_dist</th>\n",
       "      <th>o_est</th>\n",
       "      <th>o_est_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>http://dbpedia.org/resource/American_Internati...</td>\n",
       "      <td>http://dbpedia.org/ontology/district</td>\n",
       "      <td>http://dbpedia.org/resource/Voluntari</td>\n",
       "      <td>[0.35125, 0.32171202, 0.23668961, 0.1441488, 0...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.20110826, 0.17100795, 0.36559725, 0.1433617...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>http://dbpedia.org/resource/Central_High_Schoo...</td>\n",
       "      <td>http://dbpedia.org/ontology/district</td>\n",
       "      <td>http://www.capetigers.com</td>\n",
       "      <td>[0.26820898, 0.1108925, 0.091522515, -0.069246...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.11806725, -0.039811574, 0.22043014, -0.0700...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    s  \\\n",
       "12  http://dbpedia.org/resource/American_Internati...   \n",
       "24  http://dbpedia.org/resource/Central_High_Schoo...   \n",
       "\n",
       "                                       p  \\\n",
       "12  http://dbpedia.org/ontology/district   \n",
       "24  http://dbpedia.org/ontology/district   \n",
       "\n",
       "                                        o  \\\n",
       "12  http://dbpedia.org/resource/Voluntari   \n",
       "24              http://www.capetigers.com   \n",
       "\n",
       "                                                s_vec  s_is_multipart  \\\n",
       "12  [0.35125, 0.32171202, 0.23668961, 0.1441488, 0...            True   \n",
       "24  [0.26820898, 0.1108925, 0.091522515, -0.069246...            True   \n",
       "\n",
       "   s_multipart_% o_vec  o_is_multipart o_multipart_% r_vec  \\\n",
       "12             1  None           False         False  None   \n",
       "24      0.666667  None           False         False  None   \n",
       "\n",
       "    is_zero_vector_relation s_est s_est_dist  \\\n",
       "12                    False  None       None   \n",
       "24                    False  None       None   \n",
       "\n",
       "                                                o_est o_est_dist  \n",
       "12  [0.20110826, 0.17100795, 0.36559725, 0.1433617...       None  \n",
       "24  [0.11806725, -0.039811574, 0.22043014, -0.0700...       None  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show rows where the relation vector was lost\n",
    "fullVectors[fullVectors['r_vec'].isnull()].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>s_vec</th>\n",
       "      <th>s_is_multipart</th>\n",
       "      <th>s_multipart_%</th>\n",
       "      <th>o_vec</th>\n",
       "      <th>o_is_multipart</th>\n",
       "      <th>o_multipart_%</th>\n",
       "      <th>r_vec</th>\n",
       "      <th>is_zero_vector_relation</th>\n",
       "      <th>s_est</th>\n",
       "      <th>s_est_dist</th>\n",
       "      <th>o_est</th>\n",
       "      <th>o_est_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>http://dbpedia.org/resource/Sacramento_Norther...</td>\n",
       "      <td>http://dbpedia.org/ontology/typeOfElectrification</td>\n",
       "      <td>http://dbpedia.org/resource/Sacramento_Norther...</td>\n",
       "      <td>[-0.18791135, -0.34605, 0.3797767, -0.08740999...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.18791135, -0.34605, 0.3797767, -0.08740999...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.14952804, -0.32358798, 0.047327846, -0.0316...</td>\n",
       "      <td>0.887354</td>\n",
       "      <td>[-0.52535075, -0.368512, 0.71222556, -0.143201...</td>\n",
       "      <td>0.792689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>http://dbpedia.org/resource/Malmö_Borgarskola</td>\n",
       "      <td>http://dbpedia.org/ontology/district</td>\n",
       "      <td>http://dbpedia.org/resource/Malmö</td>\n",
       "      <td>[-0.44101, -0.69345, -0.10646, 0.20029, 0.3706...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[-0.44101, -0.69345, -0.10646, 0.20029, 0.3706...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.29086828, -0.5427459, -0.23536763, 0.20107...</td>\n",
       "      <td>0.953179</td>\n",
       "      <td>[-0.5911517, -0.84415406, 0.022447623, 0.19950...</td>\n",
       "      <td>0.963126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      s  \\\n",
       "1445  http://dbpedia.org/resource/Sacramento_Norther...   \n",
       "1797      http://dbpedia.org/resource/Malmö_Borgarskola   \n",
       "\n",
       "                                                      p  \\\n",
       "1445  http://dbpedia.org/ontology/typeOfElectrification   \n",
       "1797               http://dbpedia.org/ontology/district   \n",
       "\n",
       "                                                      o  \\\n",
       "1445  http://dbpedia.org/resource/Sacramento_Norther...   \n",
       "1797                  http://dbpedia.org/resource/Malmö   \n",
       "\n",
       "                                                  s_vec  s_is_multipart  \\\n",
       "1445  [-0.18791135, -0.34605, 0.3797767, -0.08740999...            True   \n",
       "1797  [-0.44101, -0.69345, -0.10646, 0.20029, 0.3706...            True   \n",
       "\n",
       "     s_multipart_%                                              o_vec  \\\n",
       "1445             1  [-0.18791135, -0.34605, 0.3797767, -0.08740999...   \n",
       "1797           0.5  [-0.44101, -0.69345, -0.10646, 0.20029, 0.3706...   \n",
       "\n",
       "      o_is_multipart o_multipart_%  \\\n",
       "1445            True             1   \n",
       "1797           False         False   \n",
       "\n",
       "                                                  r_vec  \\\n",
       "1445  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1797  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "      is_zero_vector_relation  \\\n",
       "1445                     True   \n",
       "1797                     True   \n",
       "\n",
       "                                                  s_est s_est_dist  \\\n",
       "1445  [0.14952804, -0.32358798, 0.047327846, -0.0316...   0.887354   \n",
       "1797  [-0.29086828, -0.5427459, -0.23536763, 0.20107...   0.953179   \n",
       "\n",
       "                                                  o_est o_est_dist  \n",
       "1445  [-0.52535075, -0.368512, 0.71222556, -0.143201...   0.792689  \n",
       "1797  [-0.5911517, -0.84415406, 0.022447623, 0.19950...   0.963126  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show rows where the relation vector is a zero-vector\n",
    "fullVectors[fullVectors['is_zero_vector_relation'] == True].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 20896\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>vec</th>\n",
       "      <th>is_multipart</th>\n",
       "      <th>multipart_%</th>\n",
       "      <th>est</th>\n",
       "      <th>est_dist</th>\n",
       "      <th>total</th>\n",
       "      <th>mean_est_dist</th>\n",
       "      <th>min_est_dist</th>\n",
       "      <th>max_est_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://dbpedia.org/resource/'Asir_Province</td>\n",
       "      <td>[-0.038862, -0.39208, 0.57892, 0.070221, 0.742...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[-0.5358629, -0.9879053, 0.49990124, -0.509186...</td>\n",
       "      <td>0.582015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582015</td>\n",
       "      <td>0.582015</td>\n",
       "      <td>0.582015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://dbpedia.org/resource/13th_Street_Repert...</td>\n",
       "      <td>[0.5617967, 0.050450005, 0.026729502, 0.368527...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5291708, 0.11075393, 0.079255015, 0.0315063...</td>\n",
       "      <td>0.797982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797982</td>\n",
       "      <td>0.797982</td>\n",
       "      <td>0.797982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                node  \\\n",
       "0         http://dbpedia.org/resource/'Asir_Province   \n",
       "1  http://dbpedia.org/resource/13th_Street_Repert...   \n",
       "\n",
       "                                                 vec  is_multipart  \\\n",
       "0  [-0.038862, -0.39208, 0.57892, 0.070221, 0.742...          True   \n",
       "1  [0.5617967, 0.050450005, 0.026729502, 0.368527...          True   \n",
       "\n",
       "  multipart_%                                                est  est_dist  \\\n",
       "0         0.5  [-0.5358629, -0.9879053, 0.49990124, -0.509186...  0.582015   \n",
       "1           1  [0.5291708, 0.11075393, 0.079255015, 0.0315063...  0.797982   \n",
       "\n",
       "   total  mean_est_dist  min_est_dist  max_est_dist  \n",
       "0      1       0.582015      0.582015      0.582015  \n",
       "1      1       0.797982      0.797982      0.797982  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length: {len(nodeVectors)}\")\n",
    "nodeVectors.head(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "nodeVectors[np.bitwise_and(nodeVectors['est_dist'] < 0.5, nodeVectors['total'] > 9)].sort_values(by=['total'], ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = 18493\n",
    "fullVectors[np.bitwise_or(fullVectors['o'] == nodeVectors.iloc[i]['node'], fullVectors['s'] == nodeVectors.iloc[i]['node'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 151\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>is_multipart</th>\n",
       "      <th>multipart_%</th>\n",
       "      <th>est</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://cfsd.chipfalls.k12.wi.us/</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.22591428, 0.13673343, 0.4512101, 0.04979495...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://corp.ptv.vic.gov.au/projects/buses/smar...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://dbpedia.org/resource/25kVAC</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.4510494, 0.11067899, 0.73149884, 0.6687438...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://dbpedia.org/resource/3kVDC</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.4510494, 0.11067899, 0.73149884, 0.6687438...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://dbpedia.org/resource/Artistic-Athévains</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[1.1289872, -0.20345074, -0.6858917, 1.3344864...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://dbpedia.org/resource/Aspren</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.18928304, 0.008905873, -0.10518439, 0.10023...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://dbpedia.org/resource/Assicus</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.111453, 0.21223108, -0.21583664, 0.08741467...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://dbpedia.org/resource/Asti-Leku_Ikastola</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.50045294, -0.70178473, -0.5126345, -0.37087...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://dbpedia.org/resource/Athracht</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.079071015, 0.12579788, -0.17904666, 0.14626...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://dbpedia.org/resource/Austromoine</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.19645303, 0.07153387, 0.0042396113, 0.08816...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http://dbpedia.org/resource/Babette's</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.583699, -0.15524235, 0.19601205, -0.1327985...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>http://dbpedia.org/resource/Banaadir</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.006678939, -0.3835253, 0.34872505, -0.0242...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>http://dbpedia.org/resource/Başakşehir</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.41982284, -0.39472926, -0.3599917, -0.55189...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>http://dbpedia.org/resource/Belagavi</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.1912684, -0.33036742, -0.6436423, 0.963652...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>http://dbpedia.org/resource/Biotren</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.18558939, 0.057886504, 0.09516114, -0.33349...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>http://dbpedia.org/resource/Biswambhar_Bidyapitha</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.0888582, -0.9641959, -0.25077763, -0.05406...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>http://dbpedia.org/resource/Byndloss</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.08675976, -0.18382907, 0.054409124, 0.04520...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>http://dbpedia.org/resource/CBe-learn</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.43064794, -0.26111472, -0.18679458, -0.0026...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>http://dbpedia.org/resource/CNSAD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.63190293, -0.09081468, 0.18468547, 0.402166...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>http://dbpedia.org/resource/COSAT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.17909709, 0.2920703, 0.04669541, -0.009018...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>http://dbpedia.org/resource/CTrain</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.1589844, -0.15870073, 0.16356114, -0.313033...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>http://dbpedia.org/resource/Camaligan</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.19384368, 0.19027595, 0.11965096, -0.129015...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>http://dbpedia.org/resource/Chattogram</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.09176423, -0.23001656, -0.05219239, -0.460...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 node  is_multipart  \\\n",
       "0                    http://cfsd.chipfalls.k12.wi.us/         False   \n",
       "1   http://corp.ptv.vic.gov.au/projects/buses/smar...         False   \n",
       "2                  http://dbpedia.org/resource/25kVAC         False   \n",
       "3                   http://dbpedia.org/resource/3kVDC         False   \n",
       "4      http://dbpedia.org/resource/Artistic-Athévains         False   \n",
       "5                  http://dbpedia.org/resource/Aspren         False   \n",
       "6                 http://dbpedia.org/resource/Assicus         False   \n",
       "7      http://dbpedia.org/resource/Asti-Leku_Ikastola          True   \n",
       "8                http://dbpedia.org/resource/Athracht         False   \n",
       "9             http://dbpedia.org/resource/Austromoine         False   \n",
       "10              http://dbpedia.org/resource/Babette's         False   \n",
       "11               http://dbpedia.org/resource/Banaadir         False   \n",
       "12             http://dbpedia.org/resource/Başakşehir         False   \n",
       "13               http://dbpedia.org/resource/Belagavi         False   \n",
       "14                http://dbpedia.org/resource/Biotren         False   \n",
       "15  http://dbpedia.org/resource/Biswambhar_Bidyapitha          True   \n",
       "16               http://dbpedia.org/resource/Byndloss         False   \n",
       "17              http://dbpedia.org/resource/CBe-learn         False   \n",
       "18                  http://dbpedia.org/resource/CNSAD         False   \n",
       "19                  http://dbpedia.org/resource/COSAT         False   \n",
       "20                 http://dbpedia.org/resource/CTrain         False   \n",
       "21              http://dbpedia.org/resource/Camaligan         False   \n",
       "22             http://dbpedia.org/resource/Chattogram         False   \n",
       "\n",
       "   multipart_%                                                est  total  \n",
       "0        False  [0.22591428, 0.13673343, 0.4512101, 0.04979495...      1  \n",
       "1        False                                               None      1  \n",
       "2        False  [-0.4510494, 0.11067899, 0.73149884, 0.6687438...      1  \n",
       "3        False  [-0.4510494, 0.11067899, 0.73149884, 0.6687438...      1  \n",
       "4        False  [1.1289872, -0.20345074, -0.6858917, 1.3344864...      1  \n",
       "5        False  [0.18928304, 0.008905873, -0.10518439, 0.10023...      1  \n",
       "6        False  [0.111453, 0.21223108, -0.21583664, 0.08741467...      1  \n",
       "7            0  [0.50045294, -0.70178473, -0.5126345, -0.37087...      1  \n",
       "8        False  [0.079071015, 0.12579788, -0.17904666, 0.14626...      1  \n",
       "9        False  [0.19645303, 0.07153387, 0.0042396113, 0.08816...      1  \n",
       "10       False  [0.583699, -0.15524235, 0.19601205, -0.1327985...      2  \n",
       "11       False  [-0.006678939, -0.3835253, 0.34872505, -0.0242...      1  \n",
       "12       False  [0.41982284, -0.39472926, -0.3599917, -0.55189...      1  \n",
       "13       False  [-0.1912684, -0.33036742, -0.6436423, 0.963652...      1  \n",
       "14       False  [0.18558939, 0.057886504, 0.09516114, -0.33349...      1  \n",
       "15           0  [-1.0888582, -0.9641959, -0.25077763, -0.05406...      1  \n",
       "16       False  [0.08675976, -0.18382907, 0.054409124, 0.04520...      1  \n",
       "17       False  [0.43064794, -0.26111472, -0.18679458, -0.0026...      1  \n",
       "18       False  [0.63190293, -0.09081468, 0.18468547, 0.402166...      1  \n",
       "19       False  [-0.17909709, 0.2920703, 0.04669541, -0.009018...      1  \n",
       "20       False  [0.1589844, -0.15870073, 0.16356114, -0.313033...      2  \n",
       "21       False  [0.19384368, 0.19027595, 0.11965096, -0.129015...      1  \n",
       "22       False  [-0.09176423, -0.23001656, -0.05219239, -0.460...      1  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length: {len(lostNodes)}\")\n",
    "lostNodes.head(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Relation Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>vec</th>\n",
       "      <th>total</th>\n",
       "      <th>lost</th>\n",
       "      <th>zero_vector</th>\n",
       "      <th>quality</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>max_dist</th>\n",
       "      <th>mean_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://dbpedia.org/ontology/architect</td>\n",
       "      <td>[-0.104597, -0.29680526, -0.33349532, -0.35633...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696418</td>\n",
       "      <td>0.852506</td>\n",
       "      <td>0.800646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://dbpedia.org/ontology/architecturalStyle</td>\n",
       "      <td>[-0.068231784, 0.22455311, -0.084630154, 0.674...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.308163</td>\n",
       "      <td>0.854841</td>\n",
       "      <td>0.602830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://dbpedia.org/ontology/created</td>\n",
       "      <td>[-0.56977, -0.1169855, 0.25871, -0.69166005, 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://dbpedia.org/ontology/district</td>\n",
       "      <td>[-0.15014173, -0.15070407, 0.12890762, -0.0007...</td>\n",
       "      <td>8909</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991918</td>\n",
       "      <td>-0.307307</td>\n",
       "      <td>0.923979</td>\n",
       "      <td>0.609536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://dbpedia.org/ontology/governingBody</td>\n",
       "      <td>[0.18558833, -0.01517868, 0.30702534, -0.19375...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         relation  \\\n",
       "0           http://dbpedia.org/ontology/architect   \n",
       "1  http://dbpedia.org/ontology/architecturalStyle   \n",
       "2             http://dbpedia.org/ontology/created   \n",
       "3            http://dbpedia.org/ontology/district   \n",
       "4       http://dbpedia.org/ontology/governingBody   \n",
       "\n",
       "                                                 vec  total  lost  \\\n",
       "0  [-0.104597, -0.29680526, -0.33349532, -0.35633...      4     0   \n",
       "1  [-0.068231784, 0.22455311, -0.084630154, 0.674...      6     0   \n",
       "2  [-0.56977, -0.1169855, 0.25871, -0.69166005, 0...      1     0   \n",
       "3  [-0.15014173, -0.15070407, 0.12890762, -0.0007...   8909    68   \n",
       "4  [0.18558833, -0.01517868, 0.30702534, -0.19375...      1     0   \n",
       "\n",
       "   zero_vector   quality  min_dist  max_dist  mean_dist  \n",
       "0            0  1.000000  0.696418  0.852506   0.800646  \n",
       "1            0  1.000000  0.308163  0.854841   0.602830  \n",
       "2            0  1.000000  1.000000  1.000000   1.000000  \n",
       "3            4  0.991918 -0.307307  0.923979   0.609536  \n",
       "4            0  1.000000  1.000000  1.000000   1.000000  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length: {len(relationVectors)}\")\n",
    "relationVectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "relationVectors.sort_values(by=['mean_dist'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Length: {len(lostRelations)}\")\n",
    "lostRelations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate natural ambiguity\n",
    "config = {\n",
    "    'nodes': {\n",
    "        'random': [{'amount': {'num': 2}}],\n",
    "        'dist': [{\n",
    "                    'amount': {'num': 10},\n",
    "                     'param': {'dist': 1}\n",
    "                 }, {\n",
    "                     'amount': {'num': 2},\n",
    "                     'param': {'dist': 2}\n",
    "                 }]\n",
    "    },\n",
    "    'relations': {\n",
    "        'random': [{'amount': {'num': 2}}],\n",
    "        'dist': [{'amount': {'num': 5},\n",
    "                 'param': {'dist': 1}}]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random changes for testing\n",
    "config = {\n",
    "    'nodes': {\n",
    "        'random': [{'amount': {'num': 5000}}]\n",
    "    },\n",
    "    'relations': {\n",
    "        'random': [{'amount': {'num': 2500}}]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random changes for testing\n",
    "config = {\n",
    "    'nodes': {\n",
    "        'random': [{'amount': {'num': 5}}]\n",
    "    },\n",
    "    'relations': {\n",
    "        'random': [{'amount': {'num': 2}}]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete negative for testing\n",
    "config = {\n",
    "    'nodes': {\n",
    "        'negative': [{'amount': {'perc': 1}}]\n",
    "    },\n",
    "    'relations': {\n",
    "        'negative': [{'amount': {'perc': 1}}]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closeness for testing\n",
    "config = {\n",
    "    'nodes': {\n",
    "        'closeness': [{'amount': {'num': 5},\n",
    "                 'param': {'closeness': 0.2}}]\n",
    "    },\n",
    "    'relations': {\n",
    "        'closeness': [{'amount': {'num': 5},\n",
    "                 'param': {'closeness': 0.2}}]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run imports and define functions, configure the desired result\n",
    "\n",
    "#Load graph and dictionary\n",
    "convertedGraph = convertGraph(g)\n",
    "fullVectors = vectorifyGraph(convertedGraph)\n",
    "relationVectors, lostRelations = generateRelationVectors(fullVectors)\n",
    "fullVectors = calculateNodeEstimates(fullVectors, relationVectors)\n",
    "nodeVectors, lostNodes = generateNodeVectors(fullVectors)\n",
    "\n",
    "#Check outputs before continuing\n",
    "\n",
    "#Calculate ambiguity before\n",
    "ambiguityBefore = calculateAmbiguity(fullVectors, nodeVectors, relationVectors)\n",
    "logger.info(f\"Ambiguity before: {ambiguityBefore}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The ambiguify-function returns vectors according to configured methods\n",
    "res = ambiguify(config, nodeVectors, relationVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Insert new node into graph based on one random triple containing the source\n",
    "g2 = Graph()\n",
    "additions = populateAdditions(res, g2)\n",
    "\n",
    "#Calculate ambiguity after:\n",
    "newFullVectors = fullVectors.copy()\n",
    "\n",
    "if len(additions) > 0:\n",
    "    logger.info(f\"Adding {len(additions)} additional triples\")\n",
    "    vectorisedAdditions = vectorifyGraph(additions)\n",
    "    newFullVectors = newFullVectors.append(vectorisedAdditions, ignore_index = True)\n",
    "\n",
    "newRelationVectors, newLostRelations = generateRelationVectors(newFullVectors)\n",
    "newFullVectors = calculateNodeEstimates(newFullVectors, newRelationVectors)\n",
    "newNodeVectors, newLostNodes = generateNodeVectors(newFullVectors)\n",
    "\n",
    "#Calculate ambiguity after\n",
    "ambiguityAfter = calculateAmbiguity(newFullVectors, newNodeVectors, newRelationVectors)\n",
    "logger.info(f\"Ambiguity after: {ambiguityAfter}\")\n",
    "\n",
    "logger.info(f\"Ambiguity difference: {ambiguityAfter-ambiguityBefore}\")\n",
    "\n",
    "\n",
    "\n",
    "#Save additions from nodes and relations\n",
    "logger.info(f\"Saving files\")\n",
    "f = open(\"additions.ttl\", \"wb\")\n",
    "f.write(g2.serialize(format='turtle'))\n",
    "f.close()\n",
    "\n",
    "#Save graph with additions\n",
    "g3 = g+g2\n",
    "f = open(\"appendedKG.ttl\", \"wb\")\n",
    "f.write(g3.serialize(format='turtle'))\n",
    "f.close()\n",
    "logger.info(f\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: for all appends: \n",
    "#https://stackoverflow.com/questions/50501787/python-pandas-user-warning-sorting-because-non-concatenation-axis-is-not-aligne\n",
    "\n",
    "#TODO: random seeds\n",
    "\n",
    "#TODO: check for TODOs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns percent of ambiguity in the graph\n",
    "def calculateAmbiguity(fullVectors, nodeVectors, relationVectors):\n",
    "    #cFullVectors = fullVectors.copy()\n",
    "    #cNodeVectors = nodeVectors.copy()\n",
    "    #cRelationVectors = relationVectors.copy()\n",
    "    \n",
    "    #####for relations#####\n",
    "    \n",
    "    #group by relation type\n",
    "        #cross product group with itself\n",
    "        #apply(..) to calculate distance between both r_vec\n",
    "        #relation_distance = mean of all distances\n",
    "    #ambiguity = average weighted by count(all relation_distances)\n",
    "    #=> ambiguity values from -1..1 where 1 is the least ambiguous\n",
    "\n",
    "#     def helper1(grp):\n",
    "#         #returns the relation_distance for each group\n",
    "\n",
    "#         group = grp.copy().reset_index(drop=False)\n",
    "#         logger.info(f\"Group ({len(group)}):\\n{group['p'].iloc[0]}\\nColumns ({len(group.columns)}):\\n{group.columns}\\n\")\n",
    "#         logger.info(f\"{group}\")\n",
    "        \n",
    "#         out = group.apply(helper2, axis=1)\n",
    "#         logger.info(f\"Out:\\n{out}\\n\\n\\n\\n\\n\\n\\n\\n\\n\")\n",
    "        \n",
    "#         return np.mean(out)\n",
    "    \n",
    "#     def helper2(row):\n",
    "#         #returns the relation_distances for one group\n",
    "#         logger.info(f\"Row: {row['p']}\")\n",
    "        \n",
    "#         r_vecs = cFullVectors[cFullVectors['p'] == row['p']]['r_vec']\n",
    "#         logger.info(f\"r_vecs ({len(r_vecs)})\")\n",
    "        \n",
    "#         sims = wv.cosine_similarities(row['r_vec'], r_vecs)\n",
    "        \n",
    "#         #returns the relation_distance for one row\n",
    "#         out = np.mean(sims)\n",
    "        \n",
    "#         return out\n",
    "         \n",
    "        \n",
    "    #Remove unwanted entries\n",
    "    #cFullVectors = cFullVectors[cFullVectors['is_zero_vector_relation'] == False].dropna(subset=['r_vec']).reset_index(drop=True)\n",
    "    \n",
    "    #Broken because of https://github.com/pandas-dev/pandas/pull/29131\n",
    "    #relation_distances = fullVectors.groupby('p').apply(helper1)\n",
    "    \n",
    "    #Workaround\n",
    "    #relation_distances = cRelationVectors.apply(lambda row: helper1(fullVectors[fullVectors['p'] == row['relation']]), axis=1)\n",
    "    \n",
    "    #print(relation_distances)\n",
    "    \n",
    "    \n",
    "    ###2nd approach\n",
    "#     print(f\"Relation Vectors:\\n{cRelationVectors}\")\n",
    "    \n",
    "#     row = cRelationVectors.iloc[0]\n",
    "#     print(f\"Row: {row}\")\n",
    "#     print(f\"Row.vec:\\n{row['vec']}\")\n",
    "#     print(f\"r_vecs:\\n{list(cFullVectors[cFullVectors['p'] == row['relation']]['r_vec'])}\")\n",
    "#     print(f\"Result:\\n{wv.cosine_similarities(row['vec'], list(cFullVectors[cFullVectors['p'] == row['relation']]['r_vec']))}\")\n",
    "    \n",
    "    #cRelationVectors['mean_dist'] = cRelationVectors.apply(lambda row: np.mean(wv.cosine_similarities(row['vec'], list(cFullVectors[cFullVectors['p'] == row['relation']]['r_vec']))), axis=1)\n",
    "    \n",
    "    weights = relationVectors['total'] - relationVectors['lost'] - relationVectors['zero_vector']\n",
    "    relAmbig = np.average(relationVectors['mean_dist'], weights=weights)\n",
    "    \n",
    "    #####for nodes (improved)#####\n",
    "    \n",
    "    #for node in nodeVectors:\n",
    "        #node_estimate = average weighted by relations dist to mean(all connected nodes + their relation to node)\n",
    "    #ambiguity = average weighted by count of (distance(node_estimate, node))\n",
    "    #=> ambiguity values from -1..1 where 1 is the least ambiguous\n",
    "    \n",
    "    weights = nodeVectors['total']\n",
    "    nodeAmbig = np.average(nodeVectors['est_dist'], weights=weights)\n",
    "    \n",
    "    #bad quality of all nodes\n",
    "    #-> all relation vectors will have high average dist to mean\n",
    "    \n",
    "    #bad quality of all relations\n",
    "    #-> all relation vectors will have high average dist to mean\n",
    "    \n",
    "    #bad quality of some nodes\n",
    "    #-> node_estimate slightly wrong but better if many nodes\n",
    "    \n",
    "    #bad quality of some relations\n",
    "    #-> node_estimate very slightly wrong but better if many nodes and high relation dist to mean\n",
    "    \n",
    "    #perfect quality\n",
    "    #-> node_estimate = node and ambiguity = 1\n",
    "    \n",
    "    #do strongly connected nodes influence the outcome more? (they should)\n",
    "    #-> yes, they are included in more node_estimates\n",
    "    \n",
    "    #node and relation are included in each others calculations equally (=once) and only their means are used?\n",
    "    #-> yes\n",
    "    \n",
    "    \n",
    "    ##final composition & transformation\n",
    "    #mean of ambiguities of nodes and vectors, weight by nodes 2:1 relation\n",
    "    totAmbig = np.average([relAmbig, nodeAmbig], weights=[2, 1])\n",
    "    \n",
    "    #transform -1..1 where 1 is the least ambiguous to 0..1 where 1 is the most ambiguous\n",
    "    return 1-((1+totAmbig)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data += [['tokyo', wv['berlin'], 1]]\n",
    "data += [['tokyo', wv['tokyo'], 2]]\n",
    "data += [['vienna', wv['vienna'], 3]]\n",
    "df2 = pd.DataFrame(data, columns=['node', 'vec', 'num'])\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data += [['tokyo', wv['berlin'], 1]]\n",
    "data += [['tokyo', wv['tokyo'], 2]]\n",
    "data += [['vienna', wv['vienna'], 3]]\n",
    "df2 = pd.DataFrame(data, columns=['node', 'vec', 'num'])\n",
    "\n",
    "\n",
    "df2[['vec2', 'vec3']] = df2.apply(lambda row: pd.Series([toVector(row['node']), None]), axis=1)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test mean\n",
    "df2out = df2.groupby('node').apply(np.mean).reset_index()\n",
    "df2out['vec'] = df2.groupby('node')['vec'].apply(np.mean).reset_index()['vec']\n",
    "df2out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN vs None problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Python: {float('NaN') is None}\")\n",
    "print(f\"Numpy equal(..): {np.equal(float('NaN'), None)}\")\n",
    "print(f\"Numpy isnan(..): {np.isnan(float('NaN'))}\")\n",
    "print(f\"Pandas isnan(..): {pd.isnull(float('NaN'))}, {pd.isnull(None)}\") #Replace python checks with this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
